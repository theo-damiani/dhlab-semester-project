{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model_v3 import Model\n",
    "import loss\n",
    "import patch_utils\n",
    "import images_utils\n",
    "import images_combination\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import ast\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt, distance_transform_bf, distance_transform_cdt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import psutil\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f779f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598cf575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segmented_images(list_name):\n",
    "    \n",
    "    list_decoupes=[]\n",
    "    for i in range(0, len(list_name), 2):\n",
    "        decoupe1 = cv2.imread(f\"../ressources/DecoupeBerney_{list_name[i]}.png\", 0)\n",
    "        decoupe2 = cv2.imread(f\"../ressources/DecoupeBerney_{list_name[i+1]}.png\", 0)\n",
    "        \n",
    "        padding=500\n",
    "        decoupe1 = cv2.copyMakeBorder(decoupe1, padding, padding, padding, padding, cv2.BORDER_CONSTANT)\n",
    "        decoupe2 = cv2.copyMakeBorder(decoupe2, padding, padding, padding, padding, cv2.BORDER_CONSTANT)\n",
    "        \n",
    "        list_decoupes.append(decoupe1)\n",
    "        list_decoupes.append(decoupe2)\n",
    "        \n",
    "    return np.array(list_decoupes, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "experience_nb = \"EXP_X\"\n",
    "\n",
    "#list_cadastres_name= np.array([\"001\", \"002\"])\n",
    "\n",
    "list_cadastres_name=np.array([\n",
    "    \"001\", \"002\", \"002\", \"003\", \"003\", \"004\",\n",
    "    \"006\", \"007\", \"007\", \"008\", \"008\", \"009\",\n",
    "    \"010\", \"011\", \"013\", \"014\", \"017\", \"018\",\n",
    "    \"018\", \"025\", \"022\", \"023\", \"023\", \"024\",\n",
    "    \"025\", \"027\", \"030\", \"031\", \"036\", \"037\",\n",
    "    \"042\", \"044\", \"044\", \"045\", \"050\", \"051\",\n",
    "    \"059\", \"061\", \"069\", \"072\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1258ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(list_cadastres_name), 2):\n",
    "    \n",
    "    decoupe_list_name=np.array([list_cadastres_name[i], list_cadastres_name[i+1]])\n",
    "    \n",
    "    list_cadastres = load_segmented_images(decoupe_list_name)\n",
    "    \n",
    "    ##############################################\n",
    "    # Define Model:\n",
    "    \n",
    "    patch_numbers=20\n",
    "    patch_size=500\n",
    "\n",
    "    # For IoU:\n",
    "    distance_transform={'flag_target': False,\n",
    "                        'flag_patch': False,\n",
    "                        'flag_invert_patch': False,\n",
    "                        'flag_invert_target': True,\n",
    "                        'dt_function': distance_transform_edt}\n",
    "    \"\"\"\n",
    "    # For mask_mean_symmetric_edt:\n",
    "    distance_transform={'flag_target': False,\n",
    "                        'flag_patch': False,\n",
    "                        'flag_invert_patch': True,\n",
    "                        'flag_invert_target': False,\n",
    "                        'dt_function': distance_transform_edt}\n",
    "    \"\"\"\n",
    "\n",
    "    adjacent_patch_process={'flag_adj_patch': False,\n",
    "                            'diff_angle_adj': 0.15,\n",
    "                            'patch_adj_size': 500,\n",
    "                            'kernel_adj': np.ones((7, 7), np.uint8)}\n",
    "\n",
    "    preprocessing_parameters={'kernel_dilate_target': np.ones((7, 7), np.uint8),\n",
    "                              'kernel_dilate_patch': np.ones((7, 7), np.uint8),\n",
    "                              'resize': 7}\n",
    "\n",
    "    search_parameters={'angle_range': [0, 360],\n",
    "                      'scale_range': [0.95, 1.05]}\n",
    "\n",
    "    ga_parameters ={'max_num_iteration': 3000,\n",
    "                    'population_size':200,\n",
    "                    'mutation_probability':0.7,\n",
    "                    'elit_ratio': 0.01,\n",
    "                    'crossover_probability': 0.9,\n",
    "                    'parents_portion': 0.1,\\\n",
    "                    'parents_mut_portion': 0.2,\\\n",
    "                    'crossover_type':'uniform',\n",
    "                    'max_iteration_without_improv':None}\n",
    "\n",
    "    loss_function = loss.IntersectionOverUnion\n",
    "    #loss_function = loss.mask_mean_symmetric_edt\n",
    "    \n",
    "    classification_top_pop_variance=True\n",
    "    classification_iou=False\n",
    "    classification_H_rank=False\n",
    "\n",
    "    flag_custom_ga=True\n",
    "\n",
    "    new_model = Model(decoupe_list_name,\n",
    "                      list_cadastres,\n",
    "                      loss_function,\n",
    "                      patch_numbers=patch_numbers,\n",
    "                      patch_size=patch_size,\n",
    "                      distance_transform=distance_transform,\n",
    "                      adjacent_patch_process=adjacent_patch_process,\n",
    "                      preprocessing_parameters=preprocessing_parameters,\n",
    "                      ga_parameters=ga_parameters,\n",
    "                      search_parameters=search_parameters,\n",
    "                      classification_top_pop_variance=classification_top_pop_variance,\n",
    "                      classification_iou=classification_iou,\n",
    "                      classification_H_rank=classification_H_rank,\n",
    "                      flag_custom_ga=flag_custom_ga,\n",
    "                      experience_name=experience_nb)\n",
    "\n",
    "    ##############################################\n",
    "    # Run experiments:\n",
    "    best_scores = new_model.run()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b16cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd96b28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
